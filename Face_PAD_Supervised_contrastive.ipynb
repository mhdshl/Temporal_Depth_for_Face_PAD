{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N67PuqQKXtvd",
        "outputId": "42eb144c-4a5d-4f23-cded-5691e9a01238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRO4OKXpX0uP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "import glob\n",
        "from random import sample\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZWc-qZAYB2B"
      },
      "outputs": [],
      "source": [
        "def read_all_frames(video_path):\n",
        "  frame_list = []\n",
        "  video = cv2.VideoCapture(video_path)\n",
        "  success = True\n",
        "  while success:\n",
        "    success,frame = video.read()\n",
        "    if success == True:\n",
        "      frame = cv2.resize(frame, (64, 64), interpolation = cv2.INTER_AREA) # size reduce karny ka hai \n",
        "      frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "      frame_list.append(frame)\n",
        "    else:\n",
        "      break\n",
        "  return np.asarray(frame_list)\n",
        "\n",
        "def my_frames(data_path, N = 2):\n",
        "  # c_frames = np.empty((0, 240, 320, 3))\n",
        "  c_frames = np.empty((0, 224, 224, 3))\n",
        "  for file in os.listdir(data_path):\n",
        "    if file.endswith('.mp4'): # FOR REPLAY-ATTACK AND REPLAY-MOBILE DATASET\n",
        "      path = os.path.join(data_path, file)\n",
        "      # al_frames = read_first_N_frames(path, N)\n",
        "      al_frames = read_all_frames(path)\n",
        "      total_frames = list(np.asarray(range(0,al_frames.shape[0],1)))\n",
        "      selected_samples = sample(total_frames,N)\n",
        "      selected_frames = al_frames[selected_samples]\n",
        "      c_frames = np.concatenate((c_frames, selected_frames), axis = 0)\n",
        "      # print(c_frames.shape[0])\n",
        "  return c_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk6lbGRoYXB8"
      },
      "outputs": [],
      "source": [
        "data_path_train_real = '/content/drive/MyDrive/Anti-Spoofing_datasets/Rose_Youtu/train/real/'\n",
        "data_path_train_fixed = '/content/drive/MyDrive/Anti-Spoofing_datasets/Rose_Youtu/train/attack/'\n",
        "\n",
        "data_path_devel_real = '/content/drive/MyDrive/Anti-Spoofing_datasets/Rose_Youtu/devel/real/'\n",
        "data_path_devel_fixed = '/content/drive/MyDrive/Anti-Spoofing_datasets/Rose_Youtu/devel/attack/'\n",
        "\n",
        "data_path_test_real = '/content/drive/MyDrive/Anti-Spoofing_datasets/Rose_Youtu/test/real/'\n",
        "data_path_test_fixed = '/content/drive/MyDrive/Anti-Spoofing_datasets/Rose_Youtu/test/attack/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TOTRqePYbYw"
      },
      "outputs": [],
      "source": [
        "def load_all_data_RM(data_path_train_real, data_path_train_fixed,\n",
        "                  data_path_devel_real, data_path_devel_fixed,\n",
        "                  data_path_test_real, data_path_test_fixed, Nr=2):\n",
        "  train_real = my_frames(data_path_train_real, Nr)  # 25\n",
        "  train_fixed = my_frames(data_path_train_fixed)\n",
        "  \n",
        "  yr = train_real.shape[0]\n",
        "  ya = train_fixed.shape[0]\n",
        "  y_real = np.zeros(yr, dtype=int)\n",
        "  y_attack = np.ones(ya, dtype=int)\n",
        "  x_train = np.concatenate((train_real, train_fixed), axis = 0)\n",
        "  y_train = np.concatenate((y_real, y_attack), axis = 0)\n",
        "  \n",
        "  devel_real = my_frames(data_path_devel_real, Nr)\n",
        "  devel_fixed = my_frames(data_path_devel_fixed)\n",
        "  \n",
        "  yrd = devel_real.shape[0]\n",
        "  yad = devel_fixed.shape[0]\n",
        "  yd_real = np.zeros(yrd, dtype=int)\n",
        "  yd_attack = np.ones(yad, dtype=int)\n",
        "  x_val = np.concatenate((devel_real, devel_fixed), axis = 0) \n",
        "  y_val = np.concatenate((yd_real, yd_attack), axis = 0)\n",
        "  \n",
        "  test_real = my_frames(data_path_test_real) #, Nr\n",
        "  test_fixed = my_frames(data_path_test_fixed)\n",
        "  \n",
        "  ytr = test_real.shape[0]\n",
        "  yta = test_fixed.shape[0] \n",
        "  yt_real = np.zeros(ytr, dtype=int)\n",
        "  yt_attack = np.ones(yta, dtype=int)\n",
        "  x_test = np.concatenate((test_real, test_fixed), axis = 0)\n",
        "  y_test = np.concatenate((yt_real, yt_attack), axis = 0)\n",
        "  \n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn292TbqYm9C"
      },
      "outputs": [],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwmEiCLmY6BL",
        "outputId": "5a0e74b7-85fd-41c5-aaca-c46faec4059a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2796, 224, 224, 3) (700, 224, 224, 3) (3498, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train, x_val, y_val, x_test, y_test = load_all_data_RM(data_path_train_real, data_path_train_fixed,\n",
        "                                                                  data_path_devel_real, data_path_devel_fixed,\n",
        "                                                                  data_path_test_real, data_path_test_fixed, Nr=2)\n",
        "print(x_train.shape, x_val.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZVbKW3Qd2qW"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.02),\n",
        "        layers.RandomWidth(0.2),\n",
        "        layers.RandomHeight(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Setting the state of the normalization layer.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9p4woZ0ZAKa",
        "outputId": "6afca23f-5563-4d63-9c18-925416a347cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"casia-encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       7         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,564,807\n",
            "Trainable params: 23,519,360\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_encoder():\n",
        "    resnet = keras.applications.ResNet50V2(\n",
        "        include_top=False, weights='imagenet', input_shape=input_shape, pooling=\"avg\"\n",
        "    )\n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"casia-encoder\")\n",
        "    return model\n",
        "\n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 100\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wxQD60NZCBq"
      },
      "outputs": [],
      "source": [
        "def create_classifier(encoder, trainable=True):\n",
        "\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"RA-classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oUIlG5mZEzf"
      },
      "outputs": [],
      "source": [
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name=\"RA-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W48BNmJzZHZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8157206-0a64-4aee-eeae-1c6649ffb173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"RA-encoder_with_projection-head\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " casia-encoder (Functional)  (None, 2048)              23564807  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,827,079\n",
            "Trainable params: 23,781,632\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "44/44 [==============================] - 64s 1s/step - loss: 4.1598 - val_loss: 4.1534\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 35s 796ms/step - loss: 4.0363 - val_loss: 4.1545\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 26s 599ms/step - loss: 4.0036 - val_loss: 4.1827\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 27s 601ms/step - loss: 3.9501 - val_loss: 4.3389\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 25s 576ms/step - loss: 3.9467 - val_loss: 4.2421\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 19s 418ms/step - loss: 3.9172 - val_loss: 4.4044\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 22s 496ms/step - loss: 3.9055 - val_loss: 4.2770\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 21s 488ms/step - loss: 3.8726 - val_loss: 4.4358\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 17s 379ms/step - loss: 3.8539 - val_loss: 4.3374\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 18s 399ms/step - loss: 3.8537 - val_loss: 4.3867\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 18s 402ms/step - loss: 3.8237 - val_loss: 4.4127\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 18s 385ms/step - loss: 3.8071 - val_loss: 4.3612\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 18s 405ms/step - loss: 3.7819 - val_loss: 4.4358\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 17s 390ms/step - loss: 3.7805 - val_loss: 4.2476\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 15s 337ms/step - loss: 3.8191 - val_loss: 4.1882\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 13s 301ms/step - loss: 3.7699 - val_loss: 4.5723\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 14s 317ms/step - loss: 3.7645 - val_loss: 4.5307\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 11s 257ms/step - loss: 3.7350 - val_loss: 4.3644\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 15s 328ms/step - loss: 3.7461 - val_loss: 4.5681\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 14s 325ms/step - loss: 3.7329 - val_loss: 4.3481\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 14s 310ms/step - loss: 3.7077 - val_loss: 4.2958\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 13s 294ms/step - loss: 3.7693 - val_loss: 4.2431\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 14s 325ms/step - loss: 3.7501 - val_loss: 4.2570\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 15s 350ms/step - loss: 3.7124 - val_loss: 4.3316\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 12s 274ms/step - loss: 3.7056 - val_loss: 4.7156\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 14s 325ms/step - loss: 3.7167 - val_loss: 4.2705\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 12s 273ms/step - loss: 3.6698 - val_loss: 4.2166\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 13s 296ms/step - loss: 3.6821 - val_loss: 4.3695\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 12s 284ms/step - loss: 3.6827 - val_loss: 4.2657\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 13s 294ms/step - loss: 3.6644 - val_loss: 4.3163\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 14s 326ms/step - loss: 3.6966 - val_loss: 4.3279\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 11s 258ms/step - loss: 3.6723 - val_loss: 4.3737\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 13s 288ms/step - loss: 3.7012 - val_loss: 4.3742\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 11s 254ms/step - loss: 3.6826 - val_loss: 4.2716\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 12s 261ms/step - loss: 3.6618 - val_loss: 4.2993\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 12s 269ms/step - loss: 3.6776 - val_loss: 4.3108\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 12s 281ms/step - loss: 3.6460 - val_loss: 4.5866\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 13s 290ms/step - loss: 3.6786 - val_loss: 4.2499\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 12s 271ms/step - loss: 3.6448 - val_loss: 4.3515\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 12s 277ms/step - loss: 3.6672 - val_loss: 4.4261\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 11s 249ms/step - loss: 3.6315 - val_loss: 4.5173\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 12s 268ms/step - loss: 3.6637 - val_loss: 4.1838\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 11s 254ms/step - loss: 3.6610 - val_loss: 4.3572\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 12s 264ms/step - loss: 3.6498 - val_loss: 4.3555\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 11s 260ms/step - loss: 3.6677 - val_loss: 4.4737\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 12s 263ms/step - loss: 3.6874 - val_loss: 4.3120\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 11s 253ms/step - loss: 3.6434 - val_loss: 4.3472\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 11s 258ms/step - loss: 3.6471 - val_loss: 4.3411\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 11s 247ms/step - loss: 3.6349 - val_loss: 4.3228\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 11s 256ms/step - loss: 3.6491 - val_loss: 4.3583\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 12s 269ms/step - loss: 3.6549 - val_loss: 4.2587\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 11s 257ms/step - loss: 3.6544 - val_loss: 4.4736\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 11s 239ms/step - loss: 3.6139 - val_loss: 4.3627\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 11s 252ms/step - loss: 3.6259 - val_loss: 4.2979\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 11s 256ms/step - loss: 3.6363 - val_loss: 4.3965\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 11s 259ms/step - loss: 3.6264 - val_loss: 4.3714\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 11s 243ms/step - loss: 3.6839 - val_loss: 4.3363\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 11s 254ms/step - loss: 3.6965 - val_loss: 4.2751\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 11s 253ms/step - loss: 3.6194 - val_loss: 4.3519\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 11s 249ms/step - loss: 3.6555 - val_loss: 4.2990\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 11s 254ms/step - loss: 3.6599 - val_loss: 4.3282\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 11s 242ms/step - loss: 3.6554 - val_loss: 4.2617\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 11s 252ms/step - loss: 3.6168 - val_loss: 4.4143\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 10s 239ms/step - loss: 3.6388 - val_loss: 4.3146\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 11s 260ms/step - loss: 3.6352 - val_loss: 4.2960\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 10s 235ms/step - loss: 3.6362 - val_loss: 4.4290\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 11s 244ms/step - loss: 3.6257 - val_loss: 4.2887\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 10s 229ms/step - loss: 3.6191 - val_loss: 4.3385\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 10s 234ms/step - loss: 3.6086 - val_loss: 4.3449\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 11s 241ms/step - loss: 3.6205 - val_loss: 4.3824\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 12s 265ms/step - loss: 3.6438 - val_loss: 4.4045\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 10s 235ms/step - loss: 3.6413 - val_loss: 4.3379\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 11s 251ms/step - loss: 3.6336 - val_loss: 4.5174\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 11s 245ms/step - loss: 3.6266 - val_loss: 4.2729\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 11s 255ms/step - loss: 3.6282 - val_loss: 4.2634\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 10s 231ms/step - loss: 3.6266 - val_loss: 4.3407\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 11s 245ms/step - loss: 3.6459 - val_loss: 4.2794\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 10s 234ms/step - loss: 3.6321 - val_loss: 4.3194\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 10s 236ms/step - loss: 3.6240 - val_loss: 4.3633\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 11s 248ms/step - loss: 3.6433 - val_loss: 4.2191\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 10s 233ms/step - loss: 3.6232 - val_loss: 4.4622\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 10s 239ms/step - loss: 3.6345 - val_loss: 4.6201\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 3.6205 - val_loss: 4.4112\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 10s 239ms/step - loss: 3.6294 - val_loss: 4.5367\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 11s 242ms/step - loss: 3.6360 - val_loss: 4.4367\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 10s 238ms/step - loss: 3.6317 - val_loss: 4.2939\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 10s 230ms/step - loss: 3.6081 - val_loss: 4.3492\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 10s 233ms/step - loss: 3.6245 - val_loss: 4.4348\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 10s 235ms/step - loss: 3.6174 - val_loss: 4.2859\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 10s 231ms/step - loss: 3.6261 - val_loss: 4.2863\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 10s 231ms/step - loss: 3.6591 - val_loss: 4.4103\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 10s 231ms/step - loss: 3.6166 - val_loss: 4.3355\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 10s 231ms/step - loss: 3.6354 - val_loss: 4.3658\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 10s 237ms/step - loss: 3.6111 - val_loss: 4.4958\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 11s 249ms/step - loss: 3.6256 - val_loss: 4.6062\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 11s 241ms/step - loss: 3.5988 - val_loss: 4.4303\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 10s 239ms/step - loss: 3.6309 - val_loss: 4.2510\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 10s 235ms/step - loss: 3.6492 - val_loss: 4.3095\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 11s 247ms/step - loss: 3.6164 - val_loss: 4.2657\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 11s 240ms/step - loss: 3.5965 - val_loss: 4.3340\n"
          ]
        }
      ],
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature),\n",
        ")\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/face_pad_results/RY_supervised_contrastive_encoder.h5',\n",
        "                              verbose=0, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "\n",
        "history = encoder_with_projection_head.fit(\n",
        "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs, validation_data = (x_val, y_val),\n",
        "    callbacks = checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2WXiUysZX0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbec268-5a7d-4268-b79f-e57d6967fbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 9s 148ms/step - loss: 0.0310 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.9855 - val_sparse_categorical_accuracy: 0.9471\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 5s 114ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7804 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7692 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 4s 101ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7786 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7829 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.9614\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 5s 103ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.7743 - val_sparse_categorical_accuracy: 0.9643\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.8967 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.9169 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.8423 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.9919 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.9128 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.9452 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.9307 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.8919 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.9707 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9982 - val_loss: 1.0281 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979 - val_loss: 1.1003 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.9493 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.8624 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 5s 103ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8777 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 5.0374e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9809 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 8.6727e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.0466 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.9646 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 4s 102ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.9059 - val_sparse_categorical_accuracy: 0.9614\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.1505 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 5s 103ms/step - loss: 7.1985e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.0601 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9993 - val_loss: 1.2043 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.0260 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9993 - val_loss: 1.0261 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9989 - val_loss: 1.0296 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.2309 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 4s 101ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9957 - val_loss: 1.1549 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.9046 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.0060 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 4s 103ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.8001 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8130 - val_sparse_categorical_accuracy: 0.9629\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 4s 93ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9989 - val_loss: 1.0024 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 4s 93ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.9913 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8977 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.8773 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.8415 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9982 - val_loss: 1.0169 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.9491 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 4s 95ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.9712 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 4s 101ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.9196 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9979 - val_loss: 1.4246 - val_sparse_categorical_accuracy: 0.9457\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 4s 95ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.8436 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 4s 95ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.8411 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7585 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 4s 95ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.7839 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 4s 95ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.7132 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 5s 114ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.6284 - val_sparse_categorical_accuracy: 0.9614\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 4s 102ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7612 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 4s 101ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 6.5122e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 4s 90ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 8.3441e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.7442 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.6648 - val_sparse_categorical_accuracy: 0.9629\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7719 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9989 - val_loss: 1.0727 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.9470 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.9978 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 4s 92ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979 - val_loss: 1.0362 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.9563 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.0455 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 4.4210e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9798 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9989 - val_loss: 1.0445 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.9850 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9975 - val_loss: 1.0234 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8859 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 3.9758e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.0408 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 8.0607e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.0809 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 4s 93ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.0609 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.9978 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.8952 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.8978 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 4s 92ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7590 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 4s 96ms/step - loss: 4.5124e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7833 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 4s 100ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.9571\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.8406 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7200 - val_sparse_categorical_accuracy: 0.9586\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 4s 92ms/step - loss: 7.5483e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.8766 - val_sparse_categorical_accuracy: 0.9543\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 4s 92ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9993 - val_loss: 1.0419 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 4s 99ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.8537 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.7769 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 4s 91ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.8107 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.8994 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 4s 98ms/step - loss: 2.1330e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9419 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 4s 93ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.9270 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 4s 102ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.7757 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 4.4389e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.8372 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 4s 97ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.9557\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 4s 94ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7549 - val_sparse_categorical_accuracy: 0.9514\n",
            "110/110 [==============================] - 5s 38ms/step - loss: 1.2950 - sparse_categorical_accuracy: 0.9188\n",
            "Test accuracy: 91.88%\n"
          ]
        }
      ],
      "source": [
        "classifier = create_classifier(encoder, trainable=False)\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/face_pad_results/RY_supervised_contrastive.h5',\n",
        "                              verbose=0, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs, validation_data = (x_val, y_val), callbacks = checkpoint)\n",
        "\n",
        "classifier = load_model('/content/drive/MyDrive/face_pad_results/RY_supervised_contrastive.h5')\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D_kg_ynZhgs"
      },
      "outputs": [],
      "source": [
        "## Define performance measures\n",
        "def yoden_index(y, y_pred):\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
        "  j = (tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    f1score = 2 * tp / (2 * tp + fp + fn)\n",
        "    FAR = fp/(fp + tn)\n",
        "    FRR = fn/(fn + tp)\n",
        "    HTER = (FAR + FRR)/2\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score, 'HTER': HTER})\n",
        "\n",
        "def Show_Statistics(msg,Stats):\n",
        "  print(msg.upper())\n",
        "  print(70*'-')\n",
        "  print('Accuracy:',Stats[0])\n",
        "  print('Sensitivity:',Stats[1])\n",
        "  print('Specificity:',Stats[2])\n",
        "  print('F1-Score:',Stats[3])\n",
        "  print('HTER:',Stats[4])  \n",
        "  print('Balance Accuracy:',Stats[5])\n",
        "  print('Youden-Index:',Stats[6])\n",
        "  print(70*'-')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = classifier.predict(x_train, batch_size=64, verbose=0)\n",
        "y_train_pred = np.round(np.squeeze(y_train_pred))\n",
        "\n",
        "y_val_pred = classifier.predict(x_val, batch_size=64, verbose=0)\n",
        "y_val_pred = np.round(np.squeeze(y_val_pred))\n",
        "\n",
        "y_test_pred = classifier.predict(x_test,batch_size=64, verbose=0)\n",
        "y_test_pred = np.round(np.squeeze(y_test_pred))"
      ],
      "metadata": {
        "id": "p-awJ3fSxzOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "ojY9bOusQzWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_train.argmax(axis=1), y_train_pred.argmax(axis=1)).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "\n",
        "acc_train = accuracy_score(y_train, y_train_pred)\n",
        "Y_I_train =(tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
        "sensitivity_train = tp / (tp + fn)\n",
        "specificity_train = tn / (tn + fp)\n",
        "f1score_train = 2 * tp / (2 * tp + fp + fn)\n",
        "FAR = fp/(fp + tn)\n",
        "FRR = fn/(fn + tp)\n",
        "HTER_train = (FAR + FRR)/2\n",
        "train_bacc = balanced_accuracy_score(y_train.argmax(axis=1), y_train_pred.argmax(axis=1))\n",
        "print('Training Results')\n",
        "print(70*'-')\n",
        "print('Acc:', acc_train,'YI:', Y_I_train, 'Sen:', sensitivity_train, 'Spe:', specificity_train, '\\n F1:', f1score_train, 'HTER:', HTER_train, 'BACC:', train_bacc)"
      ],
      "metadata": {
        "id": "CTE40PkXQ31_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_val.argmax(axis=1), y_val_pred.argmax(axis=1)).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "\n",
        "acc_val = accuracy_score(y_val, y_val_pred)\n",
        "Y_I_val =(tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
        "sensitivity_val = tp / (tp + fn)\n",
        "specificity_val = tn / (tn + fp)\n",
        "f1score_val = 2 * tp / (2 * tp + fp + fn)\n",
        "FAR = fp/(fp + tn)\n",
        "FRR = fn/(fn + tp)\n",
        "HTER_val = (FAR + FRR)/2\n",
        "val_bacc = balanced_accuracy_score(y_val.argmax(axis=1), y_val_pred.argmax(axis=1))\n",
        "print('Validation Results')\n",
        "print(70*'-')\n",
        "print('Acc:', acc_val,'YI:', Y_I_val, 'Sen:', sensitivity_val, 'Spe:', specificity_val, '\\n F1:', f1score_val, 'HTER:', HTER_val, 'BACC:', val_bacc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMON39W1Q6QN",
        "outputId": "e27c95a1-4f43-40e5-b8fd-497f389ff2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162 18 9 511\n",
            "Validation Results\n",
            "----------------------------------------------------------------------\n",
            "Acc: 0.9614285714285714 YI: 0.8826923076923077 Sen: 0.9826923076923076 Spe: 0.9 \n",
            " F1: 0.9742612011439467 HTER: 0.058653846153846154 BACC: 0.9413461538461538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test[0:4500].argmax(axis=1), y_test_pred.argmax(axis=1)).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "\n",
        "acc_val = accuracy_score(y_test[0:4500], y_test_pred)\n",
        "Y_I_val =(tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
        "sensitivity_val = tp / (tp + fn)\n",
        "specificity_val = tn / (tn + fp)\n",
        "f1score_val = 2 * tp / (2 * tp + fp + fn)\n",
        "FAR = fp/(fp + tn)\n",
        "FRR = fn/(fn + tp)\n",
        "HTER_val = (FAR + FRR)/2\n",
        "val_bacc = balanced_accuracy_score(y_test[0:4500].argmax(axis=1), y_test_pred.argmax(axis=1))\n",
        "print('Testing Results')\n",
        "print(70*'-')\n",
        "print('Acc:', acc_val,'YI:', Y_I_val, 'Sen:', sensitivity_val, 'Spe:', specificity_val, '\\n F1:', f1score_val, 'HTER:', HTER_val, 'BACC:', val_bacc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LQtCHC7Q88s",
        "outputId": "147c5cb1-2791-475c-9244-7d225a036efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "682 216 68 2532\n",
            "Testing Results\n",
            "----------------------------------------------------------------------\n",
            "Acc: 0.9188107489994283 YI: 0.7333116326880247 Sen: 0.9738461538461538 Spe: 0.7594654788418709 \n",
            " F1: 0.9468960359012715 HTER: 0.13334418365598766 BACC: 0.8666558163440123\n",
            "682 216 68 2532\n",
            "Testing Results\n",
            "----------------------------------------------------------------------\n",
            "Acc: 0.9188107489994283 YI: 0.7333116326880247 Sen: 0.9738461538461538 Spe: 0.7594654788418709 \n",
            " F1: 0.9468960359012715 HTER: 0.13334418365598766 BACC: 0.8666558163440123\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}